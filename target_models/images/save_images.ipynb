{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "806aae4e",
   "metadata": {},
   "source": [
    "# Saving images for use in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb5cb1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/reid-attack/lib/python3.11/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/envs/reid-attack/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <EB3FF92A-5EB1-3EE8-AF8B-5923C1265422> /opt/anaconda3/envs/reid-attack/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/opt/anaconda3/envs/reid-attack/lib/python3.11/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/reid-attack/lib/python3.11/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/reid-attack/lib/python3.11/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/reid-attack/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d90818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, transform):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"L\")\n",
    "        img = transform(img)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_image_batches(\n",
    "    json_path,\n",
    "    image_root,\n",
    "    transform,\n",
    "    batch_size=512,\n",
    "    save_dir=\"cnn\",\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    images, paths, labels, ages, sexes = [], [], [], [], []\n",
    "    batch_idx = 0\n",
    "\n",
    "    for entry in tqdm(data, desc=\"Processing images\"):\n",
    "        img_path = os.path.join(image_root, entry[\"Path\"])\n",
    "        img_tensor = preprocess_image(img_path, transform)\n",
    "\n",
    "        if img_tensor is None:\n",
    "            continue\n",
    "\n",
    "        images.append(img_tensor)\n",
    "        paths.append(entry[\"Path\"])\n",
    "        labels.append(entry[\"Label\"])\n",
    "        ages.append(entry[\"Age\"])\n",
    "        sexes.append(1 if entry[\"Sex\"] == \"Male\" else 0)\n",
    "\n",
    "        if len(images) == batch_size:\n",
    "            # Save batch\n",
    "            save_path = os.path.join(save_dir, f\"batch_{batch_idx}.pt\")\n",
    "            torch.save({\n",
    "                \"images\": torch.stack(images).to(device),\n",
    "                \"paths\": paths,\n",
    "                \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "                \"ages\": torch.tensor(ages, dtype=torch.float32),\n",
    "                \"sexes\": torch.tensor(sexes, dtype=torch.long)\n",
    "            }, save_path)\n",
    "\n",
    "            images, paths, labels, ages, sexes = [], [], [], [], []\n",
    "            batch_idx += 1\n",
    "\n",
    "    # Save any remaining\n",
    "    if images:\n",
    "        save_path = os.path.join(save_dir, f\"batch_{batch_idx}.pt\")\n",
    "        torch.save({\n",
    "            \"images\": torch.stack(images).to(device),\n",
    "            \"paths\": paths,\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "            \"ages\": torch.tensor(ages, dtype=torch.float32),\n",
    "            \"sexes\": torch.tensor(sexes, dtype=torch.long)\n",
    "        }, save_path)\n",
    "\n",
    "    print(f\"Saved {batch_idx + 1} batches to {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5306bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f125111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 4000/4000 [00:09<00:00, 428.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 8 batches to cnn\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "\n",
    "image_root = '../../data/CheXpert_Sample'\n",
    "\n",
    "save_image_batches(\n",
    "    'cnn_images.json',\n",
    "    image_root=image_root,\n",
    "    transform=transform,\n",
    "    batch_size=512,\n",
    "    save_dir=\"cnn\",\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11f41e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 40/40 [00:00<00:00, 393.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2 batches to cnn_overfit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Overfit CNN\n",
    "\n",
    "save_image_batches(\n",
    "    'cnn_overfit_images.json',\n",
    "    image_root=image_root,\n",
    "    transform=transform,\n",
    "    batch_size=40,\n",
    "    save_dir='cnn_overfit',\n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d242e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 4000/4000 [00:08<00:00, 498.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 8 batches to vit\n"
     ]
    }
   ],
   "source": [
    "# ViT\n",
    "\n",
    "save_image_batches(\n",
    "    'vit_images.json',\n",
    "    image_root=image_root,\n",
    "    transform=transform,\n",
    "    batch_size=512,\n",
    "    save_dir='vit',\n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1046fd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 100/100 [00:00<00:00, 484.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2 batches to vit_overfit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Overfit ViT\n",
    "\n",
    "save_image_batches(\n",
    "    'vit_overfit_images.json',\n",
    "    image_root=image_root,\n",
    "    transform=transform,\n",
    "    batch_size=100,\n",
    "    save_dir='vit_overfit',\n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d66c0110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 2500/2500 [00:06<00:00, 370.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5 batches to reg\n"
     ]
    }
   ],
   "source": [
    "# Regression\n",
    "\n",
    "image_root = '../../data/CheXpert_Sample'\n",
    "\n",
    "save_image_batches(\n",
    "    'reg_images.json',\n",
    "    image_root=image_root,\n",
    "    transform=transform,\n",
    "    batch_size=512,\n",
    "    save_dir='reg',\n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17d8e818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 40/40 [00:00<00:00, 536.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1 batches to feats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Overfit CNN wtih features\n",
    "\n",
    "image_root = '../../data/CheXpert_Feats'\n",
    "\n",
    "save_image_batches(\n",
    "    'feats_images.json',\n",
    "    image_root=image_root,\n",
    "    transform=transform,\n",
    "    batch_size=512,\n",
    "    save_dir='feats',\n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e17942f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reid-attack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
